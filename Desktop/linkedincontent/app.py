import streamlit as st
import requests
import pdfplumber
import io
import re
import textwrap
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn

# --- 1. åŸºç¡€é…ç½® ---
st.set_page_config(page_title="PDF to Word (Table as Image)", layout="centered", page_icon="ğŸ“‘")

# ç»˜å›¾é…ç½® (ç¡®ä¿æ”¯æŒä¸­æ–‡)
plt.style.use('ggplot')
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'Microsoft YaHei', 'DejaVu Sans'] 
plt.rcParams['axes.unicode_minus'] = False

# --- 2. æ ¸å¿ƒå¤„ç†é€»è¾‘ ---

def extract_text_from_pdf(file_stream):
    """æå–æ–‡æœ¬"""
    text = ""
    with pdfplumber.open(file_stream) as pdf:
        for page in pdf.pages:
            t = page.extract_text()
            if t: text += f"\n{t}"
    return text

def call_ai_formatting(api_key, text_chunk, model="gpt-4o"):
    """
    AI ä»»åŠ¡ï¼šè¯†åˆ«è¡¨æ ¼ï¼Œç”¨æ ‡ç­¾åŒ…è£¹ã€‚
    """
    url = "https://api.nuwaapi.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    # æ ¸å¿ƒ Promptï¼šå¼ºåˆ¶æ‰“æ ‡ç­¾
    prompt = """
    You are a Document Structure Analyzer.
    Task: Reconstruct the document content.
    
    CRITICAL RULE FOR TABLES:
    1. If you see a table (rows and columns of data), you MUST output it inside strict tags:
       [[TABLE_START]]
       ... raw table content, keep it structured ...
       [[TABLE_END]]
    2. The content inside the tags MUST be the data of the table.
    
    CRITICAL RULE FOR TEXT:
    1. All non-table text must be output exactly as is (1:1).
    2. Use Markdown headers (#, ##) for titles.
    3. Do not summarize.
    """
    
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": f"{prompt}\n\nTEXT:\n{text_chunk}"}],
        "temperature": 0.1
    }
    
    try:
        res = requests.post(url, headers=headers, json=payload, timeout=180)
        if res.status_code == 200:
            return res.json()['choices'][0]['message']['content']
        return text_chunk # å¦‚æœå¤±è´¥ï¼Œè¿”å›åŸæ–‡
    except Exception as e:
        print(f"Error: {e}")
        return text_chunk

def text_to_image_bytes(table_text):
    """
    ã€æ ¸å¿ƒã€‘å°†è¡¨æ ¼æ–‡æœ¬ -> ç»˜åˆ¶æˆ matplotlib å›¾ç‰‡ -> è¿”å›äºŒè¿›åˆ¶æµ
    """
    try:
        # 1. è§£ææ•°æ®
        lines = table_text.strip().split('\n')
        data = []
        for line in lines:
            # ç®€å•æ¸…æ´—
            if not line.strip(): continue
            if set(line.strip()) <= {'|', '-', ' '}: continue # è·³è¿‡åˆ†å‰²çº¿
            
            # æŒ‰ç«–çº¿æˆ–å¤šç©ºæ ¼æ‹†åˆ†
            if '|' in line:
                cells = [c.strip() for c in line.split('|') if c.strip() != '']
            else:
                cells = [c.strip() for c in re.split(r'\s{2,}', line.strip())]
            
            if cells: data.append(cells)
            
        if not data: return None

        # è¡¥é½åˆ—
        max_cols = max(len(row) for row in data)
        final_data = [row + [""]*(max_cols-len(row)) for row in data]
        
        headers = final_data[0]
        body = final_data[1:]
        if not body: body = [[""]*len(headers)]

        # 2. ç»˜å›¾
        df = pd.DataFrame(body, columns=headers)
        
        # åŠ¨æ€è®¡ç®—å°ºå¯¸
        row_heights = []
        col_width = 20
        for row in body:
            max_lines = 1
            for item in row:
                lines_count = len(textwrap.wrap(str(item), width=col_width))
                max_lines = max(max_lines, lines_count)
            row_heights.append(max_lines)

        base_h = 0.5
        total_h = 0.8 + sum([h*base_h for h in row_heights])
        total_w = min(len(headers)*3.0, 11)

        fig, ax = plt.subplots(figsize=(total_w, total_h))
        ax.axis('off')
        
        table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='left')
        table.auto_set_font_size(False)
        table.set_fontsize(11)
        
        # ç¾åŒ–è¡¨æ ¼æ ·å¼
        cells = table.get_celld()
        for (row, col), cell in cells.items():
            cell.set_edgecolor('#bfbfbf')
            cell.set_linewidth(1)
            cell.set_text_props(position=(0.02, cell.get_text_props()['position'][1]))
            
            if row == 0:
                cell.set_facecolor('#2c3e50')
                cell.set_text_props(color='white', weight='bold', ha='center')
                cell.set_height(0.8/total_h)
            else:
                cell.set_facecolor('#f8f9fa' if row%2 else 'white')
                cell.set_text_props(color='black', wrap=True)
                cell.set_height((row_heights[row-1]*base_h)/total_h)

        img_buf = io.BytesIO()
        plt.savefig(img_buf, format='png', bbox_inches='tight', dpi=300, pad_inches=0.1)
        plt.close(fig)
        img_buf.seek(0)
        return img_buf

    except Exception as e:
        print(f"Plot Error: {e}")
        return None

def generate_perfect_word(ai_output_text):
    """
    ç”Ÿæˆ Word æ–‡æ¡£ã€‚
    é€»è¾‘ï¼šè§£æ [[TABLE]] æ ‡ç­¾ -> è½¬å›¾ç‰‡æ’å…¥ï¼›å…¶ä»– -> æ–‡æœ¬æ’å…¥ã€‚
    """
    doc = Document()
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Calibri'
    font.size = Pt(11)
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'SimHei') # è®¾ç½®ä¸­æ–‡å­—ä½“
    
    # åˆ‡åˆ†å†…å®¹
    pattern = re.compile(r'(\[\[TABLE_START\]\][\s\S]*?\[\[TABLE_END\]\])')
    parts = pattern.split(ai_output_text)
    
    doc.add_heading('Research Report Translation', 0)
    
    for part in parts:
        if "[[TABLE_START]]" in part:
            # === å¤„ç†è¡¨æ ¼ ===
            raw_table = part.replace("[[TABLE_START]]", "").replace("[[TABLE_END]]", "").strip()
            img_bytes = text_to_image_bytes(raw_table)
            
            if img_bytes:
                p = doc.add_paragraph()
                p.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = p.add_run()
                # æ’å…¥é«˜æ¸…å›¾ç‰‡
                run.add_picture(img_bytes, width=Inches(6.0))
            else:
                doc.add_paragraph(raw_table) # å¤±è´¥å›é€€
        else:
            # === å¤„ç†æ–‡æœ¬ ===
            lines = part.strip().split('\n')
            for line in lines:
                line = line.strip()
                if not line: continue
                
                if line.startswith('# '): doc.add_heading(line[2:], 1)
                elif line.startswith('## '): doc.add_heading(line[3:], 2)
                elif line.startswith('### '): doc.add_heading(line[4:], 3)
                elif line.startswith('- ') or line.startswith('* '): 
                    doc.add_paragraph(line[2:], style='List Bullet')
                else:
                    doc.add_paragraph(line)
                    
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# --- 3. UI ç•Œé¢ ---

st.title("ğŸ“‘ PDF è½¬ Word (è¡¨æ ¼å®Œç¾è½¬å›¾ç‰ˆ)")
st.markdown("""
**æ ¸å¿ƒé€»è¾‘ï¼š**
1. æå– PDF å†…å®¹ã€‚
2. AI è‡ªåŠ¨è¯†åˆ«å¹¶æå–æ‰€æœ‰è¡¨æ ¼ã€‚
3. **ç¨‹åºè‡ªåŠ¨å°†è¡¨æ ¼ç»˜åˆ¶æˆé«˜æ¸…å›¾ç‰‡**ã€‚
4. ç”Ÿæˆ **Word æ–‡æ¡£**ã€‚

ğŸ‘‰ **ä½¿ç”¨æ–¹æ³•ï¼š** ä¸‹è½½ Word æ–‡æ¡£ -> æ‰“å¼€ -> å…¨é€‰å¤åˆ¶ (Ctrl+A, Ctrl+C) -> ç²˜è´´åˆ°ä»»ä½•åœ°æ–¹ã€‚è¿™æ˜¯ä¿è¯æ ¼å¼ä¸ä¹±çš„å”¯ä¸€æ–¹æ³•ã€‚
""")

api_key = st.text_input("è¾“å…¥ API Key", value="sk-3UIO8MwTblfyQuEZz2WUCzQOuK4QwwIPALVcNxFFNUxJayu7", type="password")
uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type=['pdf'])

if uploaded_file and st.button("å¼€å§‹è½¬æ¢"):
    if not api_key:
        st.error("è¯·è¾“å…¥ API Key")
    else:
        # 1. æå–æ–‡å­—
        with st.spinner("1/3 æ­£åœ¨è¯»å– PDF..."):
            raw_text = extract_text_from_pdf(uploaded_file)
        
        # 2. AI ç»“æ„åŒ–å¤„ç†
        # åˆ†å—å¤„ç†ä»¥é˜²è¶…é•¿ï¼Œç®€å•èµ·è§è¿™é‡Œåˆ‡å‰ 5000 å­—æ¼”ç¤ºï¼Œå®é™…ä½¿ç”¨å¯å¾ªç¯
        chunks = [raw_text[i:i+4000] for i in range(0, len(raw_text), 4000)]
        full_ai_text = []
        
        progress = st.progress(0)
        for i, chunk in enumerate(chunks):
            with st.spinner(f"2/3 AI æ­£åœ¨è¯†åˆ«è¡¨æ ¼ä¸æ–‡æœ¬ (Part {i+1}/{len(chunks)})..."):
                processed = call_ai_formatting(api_key, chunk)
                full_ai_text.append(processed)
            progress.progress((i+1)/len(chunks))
            
        final_text = "\n".join(full_ai_text)
        
        # 3. ç”Ÿæˆ Word
        with st.spinner("3/3 æ­£åœ¨ç»˜åˆ¶è¡¨æ ¼å›¾ç‰‡å¹¶ç”Ÿæˆ Word..."):
            word_file = generate_perfect_word(final_text)
            
        st.success("âœ… è½¬æ¢å®Œæˆï¼è¡¨æ ¼å·²å…¨éƒ¨è½¬åŒ–ä¸ºå›¾ç‰‡ã€‚")
        
        # 4. ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½æœ€ç»ˆ Word æ–‡æ¡£",
            data=word_file,
            file_name=f"Converted_{datetime.now().strftime('%H%M')}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
        
        st.info("ğŸ’¡ æç¤ºï¼šä¸‹è½½åæ‰“å¼€ Wordï¼Œé‡Œé¢çš„è¡¨æ ¼å°±æ˜¯å›¾ç‰‡äº†ã€‚ä½ å¯ä»¥éšæ„å¤åˆ¶ç²˜è´´ï¼Œæ ¼å¼æ°¸è¿œä¸ä¼šä¹±ã€‚")
