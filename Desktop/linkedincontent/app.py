import streamlit as st
import requests
import pdfplumber
import io
import time
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

# --- å…¨å±€é…ç½® ---
st.set_page_config(page_title="ç¤¾åª’æ–‡æ¡ˆ Agent", layout="wide", page_icon="ğŸ“±")
plt.style.use('ggplot')
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# --- çŠ¶æ€ç®¡ç† ---
if 'history' not in st.session_state:
    st.session_state['history'] = []
if 'current_report' not in st.session_state:
    st.session_state['current_report'] = None

# --- æ ¸å¿ƒå‡½æ•° ---

def extract_text_from_pdf(uploaded_file):
    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for i, page in enumerate(pdf.pages):
            page_text = page.extract_text()
            if page_text:
                text += f"\n\n====== [PAGE {i+1}] ======\n{page_text}"
    return text

def split_text_into_chunks(text, chunk_size=2000):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

def call_ai_api(api_key, base_url, model_name, messages, temperature=0.3):
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model_name, "messages": messages, "temperature": temperature, "stream": False}
    try:
        # é’ˆå¯¹ Gemini ç³»åˆ—ï¼Œå¤„ç†é•¿æ–‡æœ¬å¯èƒ½éœ€è¦æ›´é•¿å“åº”æ—¶é—´ï¼Œè®¾ç½®è¶…æ—¶ä¸º 300ç§’
        response = requests.post(base_url, headers=headers, json=payload, timeout=300)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            return None 
    except:
        return None

def create_table_image(markdown_table_lines):
    """Markdownè¡¨æ ¼è½¬å›¾ç‰‡"""
    try:
        clean_rows = [line for line in markdown_table_lines if not set(line.replace('|', '').strip()) == {'-'}]
        if len(clean_rows) < 2: return None
        headers = [h.strip() for h in clean_rows[0].split('|') if h.strip()]
        data = []
        for row in clean_rows[1:]:
            row_data = [c.strip() for c in row.split('|') if c.strip() or c==""]
            if len(row_data) > len(headers): row_data = row_data[:len(headers)]
            if len(row_data) < len(headers): row_data += [""] * (len(headers) - len(row_data))
            data.append(row_data)
        if not data: return None
        
        df = pd.DataFrame(data, columns=headers)
        fig, ax = plt.subplots(figsize=(12, len(data)*0.6 + 1.5))
        ax.axis('off')
        table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 1.8)
        
        for (row, col), cell in table.get_celld().items():
            cell.set_edgecolor('#cccccc')
            if row == 0:
                cell.set_facecolor('#2c3e50')
                cell.set_text_props(color='white', weight='bold')
            else:
                cell.set_facecolor('#f8f9fa' if row % 2 else 'white')
        
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=300)
        plt.close(fig)
        img_buffer.seek(0)
        return img_buffer
    except:
        return None

def generate_word_doc(content_text, model_name):
    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Arial'
    style.font.size = Pt(10.5)
    
    doc.add_heading('Analysis Report', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"Source: Uploaded PDF | Model: {model_name}").alignment = WD_ALIGN_PARAGRAPH.RIGHT
    doc.add_paragraph("_" * 50)

    lines = content_text.split('\n')
    inside_table = False
    table_buffer = []

    for line in lines:
        stripped = line.strip()
        is_table_row = stripped.startswith('|') and stripped.endswith('|')
        
        if is_table_row:
            inside_table = True
            table_buffer.append(stripped)
        else:
            if inside_table:
                img = create_table_image(table_buffer)
                if img: 
                    doc.add_picture(img, width=Inches(6.5))
                    doc.add_paragraph("")
                inside_table = False
                table_buffer = []
            
            if stripped.startswith('# '): doc.add_heading(stripped.replace('#','').strip(), 1)
            elif stripped.startswith('## '): doc.add_heading(stripped.replace('#','').strip(), 2)
            elif stripped.startswith('### '): doc.add_heading(stripped.replace('#','').strip(), 3)
            elif stripped.startswith('- '): doc.add_paragraph(stripped[2:], style='List Bullet')
            elif stripped: doc.add_paragraph(stripped)

    if inside_table and table_buffer:
        img = create_table_image(table_buffer)
        if img: doc.add_picture(img, width=Inches(6.5))
    
    bio = io.BytesIO()
    doc.save(bio)
    return bio

# --- UI & Logic ---
with st.sidebar:
    st.title("ğŸ—ƒï¸ å†å²è®°å½•")
    if st.session_state['history']:
        for i, item in enumerate(reversed(st.session_state['history'])):
            if st.button(f"Load: {item['time']}", key=f"hist_{i}"):
                st.session_state['current_report'] = item
                st.rerun()
    
    st.divider()
    # é»˜è®¤API Key (å»ºè®®ç”Ÿäº§ç¯å¢ƒç½®ç©º)
    api_key = st.text_input("API Key", value="sk-3UIO8MwTblfyQuEZz2WUCzQOuK4QwwIPALVcNxFFNUxJayu7", type="password")
    
    # === æ¨¡å‹åˆ—è¡¨æ›´æ–° ===
    model_options = [
        "gemini-3-pro", 
        "gemini-2.5-pro", 
        "qwen-max", 
        "gpt-4o"
    ]
    model_name = st.selectbox("é€‰æ‹©æ¨¡å‹ (Model)", model_options)

st.title("ğŸ“± ç¤¾åª’æ–‡æ¡ˆ Agent")

uploaded_file = st.file_uploader("ä¸Šä¼  PDF èµ„æ–™", type=['pdf'])

if uploaded_file and st.button("ğŸ”¥ å¼€å§‹ç”Ÿæˆæ–‡æ¡ˆ & æŠ¥å‘Š"):
    api_url = "https://api.nuwaapi.com/v1/chat/completions"
    
    # 1. è§£æ
    with st.spinner("ğŸ“– æ­£åœ¨è¯»å– PDF å†…å®¹..."):
        raw_text = extract_text_from_pdf(uploaded_file)

    # 2. é€æ®µè½¬åŒ– (å¸¦æ™ºèƒ½ä¿åº•)
    chunks = split_text_into_chunks(raw_text, chunk_size=2000)
    full_article_parts = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, chunk in enumerate(chunks):
        status_text.markdown(f"**ğŸ”„ è§£æå¤„ç†ä¸­: Part {i+1}/{len(chunks)}**")
        
        prompt = """
        You are a Document Digitizer.
        Task: Convert raw PDF text to Markdown.
        Rules:
        1. **KEEP EVERY DETAIL**. No summarizing.
        2. **Format Tables** as Markdown (|...|).
        3. **References/URLs**: Keep them exactly as is.
        """
        msg = [{"role": "user", "content": f"{prompt}\n\nCONTENT:\n{chunk}"}]
        
        # é‡è¯•é€»è¾‘
        chunk_res = None
        for attempt in range(2):
            chunk_res = call_ai_api(api_key, api_url, model_name, msg)
            if chunk_res: break
            time.sleep(1)
        
        # æ™ºèƒ½ä¿åº•
        if chunk_res:
            full_article_parts.append(chunk_res)
        else:
            fallback_text = f"\n\n> âš ï¸ (Note: Section {i+1} raw content preserved due to processing complexity)\n\n{chunk}\n\n"
            full_article_parts.append(fallback_text)
            
        progress_bar.progress((i + 1) / len(chunks))

    final_article = "\n\n".join(full_article_parts)
    status_text.success("âœ… å†…å®¹è§£æå®Œæˆï¼")

    # 3. ç¤¾åª’ç”Ÿæˆ (æ–°é—»/çƒ­ç‚¹å¯¼å‘å‹)
    with st.spinner("ğŸ“° æ­£åœ¨æç‚¼çƒ­ç‚¹å¹¶æ’°å†™ç¤¾åª’æ–‡æ¡ˆ..."):
        
        # æ„é€ ä¸Šä¸‹æ–‡ï¼šå¤´ + å°¾ï¼Œç¡®ä¿åŒ…å«æœ€æ–°ç»“è®º
        context_head = final_article[:5000]
        context_tail = final_article[-8000:] if len(final_article) > 8000 else ""
        social_context = context_head + "\n\n[...SKIPPING MIDDLE SECTIONS...]\n\n" + context_tail
        
        social_prompt = """
        You are a Viral Social Media Copywriter. Write content based on the report.
        
        **CRITICAL INSTRUCTION**: 
        - **FOCUS ON THE "NEW"**: Prioritize the most recent events, financial numbers, and future guidance (e.g., 2025 outlook).
        - **STYLE**: High energy, professional but engaging.
        
        **Platforms**:
        1. **LinkedIn**: Professional insight. Focus on "Key Takeaways" & "Strategic Direction".
        2. **Twitter (Thread)**: 5 tweets. Breaking news style. Use ğŸš¨ emojis.
        3. **Xiaohongshu (å°çº¢ä¹¦)**: "Big News!" style. Focus on money/trend. Emoji heavy.
        4. **Reddit**: Analytical discussion starter.
        
        Output in the requested languages. Split with '==='.
        """
        
        msg_social = [{"role": "user", "content": f"{social_prompt}\n\nREPORT CONTENT:\n{social_context}"}]
        social_res = call_ai_api(api_key, api_url, model_name, msg_social)
        
        if not social_res: social_res = "âš ï¸ ç¤¾åª’ç”Ÿæˆè¶…æ—¶ï¼Œè¯·å°è¯•é‡æ–°ç”Ÿæˆã€‚"

    # 4. ç”Ÿæˆ Word
    with st.spinner("ğŸ’¾ æ­£åœ¨æ‰“åŒ… Word æ–‡æ¡£..."):
        word_bio = generate_word_doc(final_article, model_name)

    # 5. å­˜æ¡£
    report_data = {
        "time": datetime.now().strftime("%H:%M"),
        "filename": uploaded_file.name,
        "article": final_article,
        "social": social_res,
        "word_data": word_bio.getvalue()
    }
    st.session_state['current_report'] = report_data
    st.session_state['history'].append(report_data)
    st.rerun()

# --- ç»“æœå±•ç¤º ---
current = st.session_state['current_report']

if current:
    st.divider()
    st.markdown(f"## ğŸ“Š å½“å‰é¡¹ç›®: {current['filename']}")
    col1, col2 = st.columns([6, 4])
    
    with col1:
        st.download_button(
            "ğŸ“¥ ä¸‹è½½è¯¦ç»† Word æŠ¥å‘Š",
            data=current['word_data'],
            file_name=f"Report_{current['time']}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
        with st.expander("ğŸ“„ åŸå§‹å†…å®¹é¢„è§ˆ", expanded=False):
            st.markdown(current['article'])

    with col2:
        st.success("ğŸ”¥ å·²ç”Ÿæˆç¤¾åª’æ–‡æ¡ˆ")
        st.text_area("ä¸€é”®å¤åˆ¶æ‰€æœ‰æ–‡æ¡ˆ", value=current['social'], height=600)

elif not uploaded_file:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ–‡ä»¶ã€‚å»ºè®®ä¼˜å…ˆä½¿ç”¨ 'gemini-3-pro' å¤„ç†é•¿æ–‡æ¡£ã€‚")