import streamlit as st
import requests
import pdfplumber
import io
import time
import textwrap
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn

# --- å…¨å±€é…ç½® ---
st.set_page_config(page_title="Pro Research Agent (Visual Edition)", layout="wide", page_icon="ğŸ’")

# é…ç½®ç»˜å›¾é£æ ¼ (è§£å†³ä¸­æ–‡ä¹±ç å’Œæ ·å¼é—®é¢˜)
plt.style.use('ggplot')
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'DejaVu Sans', 'Microsoft YaHei'] 
plt.rcParams['axes.unicode_minus'] = False

# --- çŠ¶æ€ç®¡ç† ---
if 'history' not in st.session_state:
    st.session_state['history'] = []
if 'current_report' not in st.session_state:
    st.session_state['current_report'] = None

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def extract_pages_from_pdf(uploaded_file):
    """æŒ‰é¡µæå–æ–‡æœ¬ï¼Œä¿è¯ä¸Šä¸‹æ–‡å®Œæ•´"""
    pages_content = []
    with pdfplumber.open(uploaded_file) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                pages_content.append(text)
    return pages_content

def call_ai_api(api_key, base_url, model_name, messages, temperature=0.1):
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model_name, "messages": messages, "temperature": temperature, "stream": False}
    try:
        response = requests.post(base_url, headers=headers, json=payload, timeout=300)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            print(f"âš ï¸ API Error: {response.status_code}")
            return None 
    except Exception as e:
        print(f"âš ï¸ Connection Error: {e}")
        return None

def create_professional_table_image(markdown_table_lines):
    """
    ã€é«˜å®¹é”™è¡¨æ ¼ç»˜å›¾å¼•æ“ã€‘
    å°† Markdown è¡¨æ ¼æ–‡æœ¬è½¬åŒ–ä¸º Matplotlib å›¾ç‰‡å¯¹è±¡ (BytesIO)
    """
    try:
        # 1. é¢„å¤„ç†ï¼šæ¸…æ´—æ•°æ®
        clean_rows = []
        for line in markdown_table_lines:
            content = line.strip()
            # å¿…é¡»åŒ…å« | ä¸”ä¸ä»…ä»…æ˜¯åˆ†å‰²çº¿
            if '|' in content:
                # ç§»é™¤ Markdown çš„åˆ†å‰²çº¿è¡Œ (ä¾‹å¦‚ |---|---|)
                clean_check = content.replace('|', '').replace('-', '').replace(':', '').strip()
                if clean_check: 
                    clean_rows.append(content)
        
        if len(clean_rows) < 2: return None # è‡³å°‘è¦æœ‰è¡¨å¤´å’Œä¸€è¡Œæ•°æ®
        
        # 2. æ™ºèƒ½è§£æï¼šæŒ‰ | åˆ†å‰²
        data_matrix = []
        max_cols = 0
        
        for line in clean_rows:
            # ç§»é™¤é¦–å°¾å¯èƒ½å¤šä½™çš„ |
            line_pure = line.strip()
            if line_pure.startswith('|'): line_pure = line_pure[1:]
            if line_pure.endswith('|'): line_pure = line_pure[:-1]
            
            cells = [c.strip() for c in line_pure.split('|')]
            data_matrix.append(cells)
            if len(cells) > max_cols: max_cols = len(cells)

        # 3. è¡¥é½åˆ—æ•°ï¼ˆé˜²æ­¢ä¸è§„åˆ™è¡¨æ ¼æŠ¥é”™ï¼‰
        final_data = []
        for row in data_matrix:
            if len(row) < max_cols:
                row += [""] * (max_cols - len(row))
            final_data.append(row[:max_cols])
            
        if not final_data: return None

        # 4. è½¬æ¢ä¸º DataFrame
        headers = final_data[0]
        body = final_data[1:]
        if not body: body = [[""] * len(headers)] # é˜²æ­¢åªæœ‰è¡¨å¤´
        
        df = pd.DataFrame(body, columns=headers)

        # 5. ç»˜å›¾è®¡ç®—
        # åŠ¨æ€è®¡ç®—é«˜åº¦ï¼šæ ¹æ®å†…å®¹å­—æ•°å†³å®šè¡Œé«˜
        row_heights = []
        col_width_chars = 20
        for row in body:
            max_lines = 1
            for cell in row:
                # ç²—ç•¥ä¼°ç®—æ¢è¡Œè¡Œæ•°
                lines = len(textwrap.wrap(str(cell), width=col_width_chars))
                if lines > max_lines: max_lines = lines
            row_heights.append(max_lines)
            
        base_h = 0.5
        total_h = 0.8 + sum([rh * base_h for rh in row_heights]) # è¡¨å¤´ + å†…å®¹
        total_w = min(len(headers) * 3.0, 12) # å®½åº¦è‡ªé€‚åº”

        fig, ax = plt.subplots(figsize=(total_w, total_h))
        ax.axis('off')
        
        # ç»˜åˆ¶è¡¨æ ¼
        table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='left')
        
        table.auto_set_font_size(False)
        table.set_fontsize(11)
        
        # æ ·å¼ç¾åŒ–
        cells = table.get_celld()
        for (row, col), cell in cells.items():
            cell.set_edgecolor('#bfbfbf')
            cell.set_linewidth(1)
            # è®¾ç½®å†…è¾¹è·
            cell.set_text_props(position=(0.02, cell.get_text_props()['position'][1])) 
            
            if row == 0:
                cell.set_height(0.8 / total_h)
                cell.set_facecolor('#2c3e50') # æ·±è“è‰²è¡¨å¤´
                cell.set_text_props(color='white', weight='bold', ha='center', fontsize=12)
            else:
                rh_mult = row_heights[row-1]
                cell.set_height((rh_mult * base_h) / total_h)
                cell.set_facecolor('#f8f9fa' if row % 2 else '#ffffff') # æ–‘é©¬çº¹
                cell.set_text_props(color='#333333', wrap=True, ha='left', va='center')

        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=300, pad_inches=0.1)
        plt.close(fig)
        img_buffer.seek(0)
        return img_buffer

    except Exception as e:
        print(f"Table Gen Error: {e}")
        return None

def parse_content_with_images(text_content):
    """
    ã€æ ¸å¿ƒè½¬æ¢å™¨ã€‘
    å°†çº¯æ–‡æœ¬æ‹†åˆ†ä¸ºç»“æ„åŒ–åˆ—è¡¨ï¼š[TextBlock, ImageBlock, TextBlock...]
    è¿™è§£å†³äº† UI å’Œ Word æ— æ³•åŒæ—¶æ¸²æŸ“å›¾æ–‡çš„é—®é¢˜ã€‚
    """
    lines = text_content.split('\n')
    parsed_blocks = [] # List of {'type': 'text'/'image', 'content': str/bytes}
    
    current_text_buffer = []
    table_buffer = []
    inside_table = False
    
    for line in lines:
        stripped = line.strip()
        # åˆ¤å®šè¡¨æ ¼è¡Œï¼šåŒ…å«ç«–çº¿ï¼Œä¸”é•¿åº¦å¤§äº3ï¼ˆæ’é™¤å¹²æ‰°å­—ç¬¦ï¼‰
        is_potential_table_row = '|' in stripped and len(stripped) > 3
        
        if is_potential_table_row:
            if not inside_table:
                # åˆšè¿›å…¥è¡¨æ ¼ï¼Œå…ˆæŠŠä¹‹å‰çš„æ–‡æœ¬å­˜å…¥ Block
                if current_text_buffer:
                    parsed_blocks.append({'type': 'text', 'content': "\n".join(current_text_buffer)})
                    current_text_buffer = []
                inside_table = True
            table_buffer.append(stripped)
        else:
            if inside_table:
                # è¡¨æ ¼ç»“æŸï¼Œç«‹å³ç”Ÿæˆå›¾ç‰‡ Block
                img_bytes = create_professional_table_image(table_buffer)
                if img_bytes:
                    parsed_blocks.append({'type': 'image', 'content': img_bytes})
                else:
                    # å¦‚æœç”Ÿæˆå¤±è´¥ï¼ˆæ¯”å¦‚ä¸æ˜¯çœŸè¡¨æ ¼ï¼‰ï¼Œå›é€€ä¸ºæ–‡æœ¬
                    current_text_buffer.extend(table_buffer)
                
                inside_table = False
                table_buffer = []
                
            current_text_buffer.append(line)
            
    # å¤„ç†æ–‡æ¡£æœ«å°¾çš„æ®‹ç•™
    if inside_table and table_buffer:
        img_bytes = create_professional_table_image(table_buffer)
        if img_bytes:
            parsed_blocks.append({'type': 'image', 'content': img_bytes})
        else:
            current_text_buffer.extend(table_buffer)
            
    if current_text_buffer:
        parsed_blocks.append({'type': 'text', 'content': "\n".join(current_text_buffer)})
        
    return parsed_blocks

def generate_mixed_word(parsed_blocks):
    """
    æ ¹æ® Block åˆ—è¡¨ç”Ÿæˆ Wordï¼Œç¡®ä¿å›¾æ–‡æ··æ’
    """
    doc = Document()
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Calibri'
    font.size = Pt(11)
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'SimHei')
    
    # å¤´éƒ¨
    doc.add_heading('Investment Research Report', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"Generated by AI | {datetime.now().strftime('%Y-%m-%d')}", style='Normal').alignment = WD_ALIGN_PARAGRAPH.RIGHT
    doc.add_paragraph("_" * 50)

    for block in parsed_blocks:
        if block['type'] == 'text':
            # å¤„ç†æ–‡æœ¬ä¸­çš„æ ‡é¢˜æ ¼å¼
            for line in block['content'].split('\n'):
                s_line = line.strip()
                if not s_line: continue
                if s_line.startswith('# '): doc.add_heading(s_line[2:], 1)
                elif s_line.startswith('## '): doc.add_heading(s_line[3:], 2)
                elif s_line.startswith('### '): doc.add_heading(s_line[4:], 3)
                elif s_line.startswith('- ') or s_line.startswith('* '): doc.add_paragraph(s_line[2:], style='List Bullet')
                else: doc.add_paragraph(s_line)
                
        elif block['type'] == 'image':
            # æ’å…¥å›¾ç‰‡
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = p.add_run()
            try:
                block['content'].seek(0)
                run.add_picture(block['content'], width=Inches(6.2))
            except Exception:
                p.add_run("[Image Generation Error]")

    bio = io.BytesIO()
    doc.save(bio)
    return bio

# --- UI ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ—ƒï¸ å†å²è®°å½•")
    if st.session_state['history']:
        for i, item in enumerate(reversed(st.session_state['history'])):
            if st.button(f"Load: {item['time']}", key=f"hist_{i}"):
                st.session_state['current_report'] = item
                st.rerun()
    st.divider()
    api_key = st.text_input("API Key", value="sk-3UIO8MwTblfyQuEZz2WUCzQOuK4QwwIPALVcNxFFNUxJayu7", type="password")
    model_name = st.selectbox("Model", ["gemini-3-pro", "gpt-4o", "qwen-max"])

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ’ Pro Research Agent (Visual & Word Perfect)")

uploaded_file = st.file_uploader("ä¸Šä¼  PDF èµ„æ–™", type=['pdf'])

if uploaded_file and st.button("ğŸ”¥ å¼€å§‹å®Œç¾è½¬åŒ–"):
    api_url = "https://api.nuwaapi.com/v1/chat/completions"
    
    # 1. è§£æ PDF
    with st.spinner("ğŸ“– é€é¡µè¯»å– PDF..."):
        pages_list = extract_pages_from_pdf(uploaded_file)

    # 2. 1:1 æ•°å­—åŒ– (Markdown)
    full_text_parts = []
    progress_bar = st.progress(0)
    
    for i, page_text in enumerate(pages_list):
        # OCR çº§ Prompt
        prompt = """
        You are an OCR Engine. Goal: EXACT COPY.
        Rules:
        1. Output TEXT exactly as seen (Word-for-Word).
        2. Detect TABLES and format them as Markdown Tables (| Header |... |---|). 
           - DO NOT OMIT DATA. 
           - KEEP EVERY ROW.
        3. No summaries. No intro/outro text.
        """
        msg = [{"role": "user", "content": f"{prompt}\n\nCONTENT:\n{page_text}"}]
        res = call_ai_api(api_key, api_url, model_name, msg)
        
        if res: full_text_parts.append(res)
        else: full_text_parts.append(page_text) # Fallback
        
        progress_bar.progress((i + 1) / len(pages_list))

    full_article = "\n\n".join(full_text_parts)

    # 3. é¢„å¤„ç† (ç”Ÿæˆå›¾ç‰‡å¯¹è±¡) - å…³é”®æ­¥éª¤
    with st.spinner("ğŸ¨ æ­£åœ¨æ¸²æŸ“è¡¨æ ¼å›¾ç‰‡ä¸å¯è§†åŒ–è§†å›¾..."):
        # å°†æ–‡æœ¬è½¬ä¸º [Text, Image, Text] çš„ç»“æ„
        parsed_blocks = parse_content_with_images(full_article)

    # 4. ç¤¾åª’ç”Ÿæˆ
    with st.spinner("ğŸ§  æ’°å†™ç¤¾åª’æ–‡æ¡ˆ (Lead Analyst)..."):
        social_prompt = """
        Act as a Lead Analyst. Write social media content (LinkedIn, Twitter, Reddit) based on this report.
        Focus on: Logic, Catalysts, and Upside.
        """
        msg_social = [{"role": "user", "content": f"{social_prompt}\n\nREPORT:\n{full_article[:8000]}"}]
        social_res = call_ai_api(api_key, api_url, model_name, msg_social, temperature=0.7)

    # 5. ç”Ÿæˆ Word
    word_bio = generate_mixed_word(parsed_blocks)

    # 6. å­˜æ¡£
    report_data = {
        "time": datetime.now().strftime("%H:%M"),
        "filename": uploaded_file.name,
        "blocks": parsed_blocks, # å­˜ blocks ç”¨äºæ¸²æŸ“
        "social": social_res,
        "word_data": word_bio.getvalue()
    }
    st.session_state['current_report'] = report_data
    st.session_state['history'].append(report_data)
    st.rerun()

# --- ç»“æœå±•ç¤º ---
current = st.session_state['current_report']

if current:
    st.divider()
    st.markdown(f"## ğŸ“Š äº¤ä»˜: {current['filename']}")
    
    col1, col2 = st.columns([6, 4])
    
    # === å·¦ä¾§ï¼šå›¾æ–‡å¯è§†åŒ–æŠ¥å‘Š ===
    with col1:
        st.subheader("ğŸ“„ 1:1 å¯è§†åŒ–æŠ¥å‘Š (å›¾æ–‡è¿˜åŸ)")
        st.download_button(
            "ğŸ’¾ ä¸‹è½½ Word æŠ¥å‘Š (å«è¡¨æ ¼å›¾ç‰‡)",
            data=current['word_data'],
            file_name=f"Report_{current['time']}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
        st.markdown("---")
        
        # ä½¿ç”¨å®¹å™¨å¾ªç¯æ¸²æŸ“ Block
        container = st.container(height=800, border=True)
        with container:
            if 'blocks' in current:
                for block in current['blocks']:
                    if block['type'] == 'text':
                        st.markdown(block['content'])
                    elif block['type'] == 'image':
                        # ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡ï¼
                        block['content'].seek(0)
                        st.image(block['content'], use_container_width=True)

    # === å³ä¾§ï¼šç¤¾åª’æ–‡æ¡ˆ ===
    with col2:
        st.subheader("ğŸ”¥ æ·±åº¦ç¤¾åª’æ–‡æ¡ˆ")
        st.text_area("Social Media Copy", value=current.get('social', ''), height=800)

elif not uploaded_file:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼  PDFã€‚ç³»ç»Ÿå°†ç”Ÿæˆã€åŒ…å«çœŸå®è¡¨æ ¼å›¾ç‰‡ã€‘çš„ Word æŠ¥å‘Šï¼Œå¹¶åœ¨ç½‘é¡µå·¦ä¾§ç›´æ¥æ˜¾ç¤ºå›¾æ–‡æ•ˆæœã€‚")
